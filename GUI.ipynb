{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating GUI to automate Neural Network Regressor and Classifier Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, font, Canvas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import ntpath\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "# %tensorflow_version 2.x\n",
    "import tensorflow\n",
    "tensorflow.__version__\n",
    "\n",
    "# Keras specific\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using canvas function to monitor the progress of the action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "win=tk.Tk()\n",
    "blank_space =\" \" # One empty space\n",
    "\n",
    "win.geometry(\"1000x500\")\n",
    "win.title(120*blank_space+'Neural  Network GUI')\n",
    "\n",
    "# We will use canvas to check progress status of action\n",
    "cv1 = Canvas(win)\n",
    "cv2 = Canvas(win)\n",
    "cv3 = Canvas(win)\n",
    "\n",
    "red = cv1.create_oval(10,10,25,25, fill='red')\n",
    "ylw = cv2.create_oval(10,10,25,25, fill='yellow')\n",
    "grn = cv3.create_oval(10,10,25,25, fill='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions for operation of buttons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions\n",
    "\n",
    "# Importing data\n",
    "def import_data():\n",
    "    \n",
    "    global df, col, red, ylw, grn\n",
    "    \n",
    "    cv1.delete(red)\n",
    "    cv3.delete(grn)\n",
    "    \n",
    "    step1_act.delete(0,'end')\n",
    "    \n",
    "    import_file_path = filedialog.askopenfilename()\n",
    "    file = ntpath.basename(import_file_path)\n",
    "    step1_ent.insert(tk.END, file)\n",
    "    step1_act.insert(0,'Done')\n",
    "\n",
    "    df = pd.read_csv(import_file_path)\n",
    "#     print (df.head())\n",
    "\n",
    "    col = df.columns.values.tolist()\n",
    "#     print(col)\n",
    "\n",
    "    cv2.delete(ylw)\n",
    "    grn = cv3.create_oval(10,10,25,25, fill='green')\n",
    "    \n",
    "# Importing target column\n",
    "def import_trgt():\n",
    "    \n",
    "    global indata, tdata, X_train, X_test, y_train, y_test, X1, y1, red, ylw, grn\n",
    "    \n",
    "    cv1.delete(red)\n",
    "    cv3.delete(grn)\n",
    "    \n",
    "    step2_act.delete(0,'end')\n",
    "    \n",
    "    sel_col = trgt_var.get()\n",
    "    red = cv1.create_oval(10,10,25,25, fill='red')\n",
    "    step2_act.insert(0,'Not Found')\n",
    "#     print('Here 1')\n",
    "    \n",
    "    indata = df.drop([sel_col], axis=1)\n",
    "    tdata  = df.loc[:,sel_col]\n",
    "#     print('Here 2')\n",
    "\n",
    "    step2_act.delete(0,'end')\n",
    "    step2_act.insert(0,'Found')\n",
    "#     print('Here 3')    \n",
    "    \n",
    "    X1 = indata.values\n",
    "    y1 = tdata.values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.30, random_state=7)\n",
    "    \n",
    "    cv1.delete(red)\n",
    "    cv2.delete(ylw)\n",
    "    grn = cv3.create_oval(10,10,25,25, fill='green')\n",
    "\n",
    "# Training Regressor model\n",
    "def train_r():\n",
    "    \n",
    "    global model1, red, ylw, grn\n",
    "    \n",
    "    cv3.delete(grn)\n",
    "    ylw = cv2.create_oval(10,10,25,25, fill='yellow')\n",
    "    \n",
    "    step3_act1.delete(0,'end')\n",
    "    \n",
    "    model1 = Sequential()\n",
    "\n",
    "    # Normalize input data\n",
    "    model1.add(tensorflow.keras.layers.BatchNormalization(input_shape=(11,)))\n",
    "\n",
    "    model1.add(Dense(200, input_dim=11, activation= \"relu\", kernel_initializer= \"he_normal\"))\n",
    "    model1.add(BatchNormalization())\n",
    "    model1.add(Dropout(0.2)) \n",
    "    model1.add(Dense(100, activation= \"relu\", kernel_initializer= \"he_normal\"))\n",
    "    model1.add(BatchNormalization())\n",
    "    model1.add(Dropout(0.2)) \n",
    "    model1.add(Dense(50, activation= \"relu\", kernel_initializer= \"he_normal\"))\n",
    "    model1.add(BatchNormalization())\n",
    "    model1.add(Dropout(0.2)) \n",
    "\n",
    "    # Output node\n",
    "    model1.add(Dense(1))\n",
    "    \n",
    "    # Compile\n",
    "    model1.compile(loss= 'mse' , optimizer='adam', metrics='mse')\n",
    "    result1 = model1.fit(X_train, y_train, batch_size=10, validation_split=0.2, epochs=100);\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "    pred_train= model1.predict(X_train)\n",
    "    print(np.sqrt(mean_squared_error(y_train,pred_train)))\n",
    "\n",
    "    step3_act1.insert(0,'Network Trained')\n",
    "    \n",
    "    cv2.delete(ylw)\n",
    "    grn = cv3.create_oval(10,10,25,25, fill='green')\n",
    "    \n",
    "#     pred= model1.predict(X_test)\n",
    "#     print(np.sqrt(mean_squared_error(y_test,pred))) \n",
    "\n",
    "# Saving Regressor model\n",
    "def save_r():\n",
    "    \n",
    "    global model1, red, ylw, grn\n",
    "    \n",
    "    cv3.delete(grn)\n",
    "    ylw = cv2.create_oval(10,10,25,25, fill='yellow')\n",
    "    \n",
    "    step3_act2.delete(0,'end')\n",
    "    model1.save('Regression.h5')\n",
    "    step3_act2.insert(0,'Model Saved')\n",
    "    \n",
    "    cv2.delete(ylw)\n",
    "    grn = cv3.create_oval(10,10,25,25, fill='green')\n",
    "    \n",
    "    \n",
    "# Training Classifier model\n",
    "def train_c():\n",
    "    \n",
    "    global X_train1, X_test1, y_train1, y_test1, X2, y2, model2, red, ylw, grn\n",
    "    \n",
    "    cv3.delete(grn)\n",
    "    ylw = cv2.create_oval(10,10,25,25, fill='yellow')\n",
    "    \n",
    "    step4_act1.delete(0,'end')\n",
    "    X2 = indata.values\n",
    "    y2 = tdata.values\n",
    "\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(X2, y2, test_size=0.30, random_state=7)\n",
    "    \n",
    "    # converting y data into categorical (one-hot encoding)\n",
    "    y_train1 = to_categorical(y_train1)\n",
    "    y_test1 = to_categorical(y_test1)\n",
    "    \n",
    "    # Building the NN regressor model\n",
    "    model2 = Sequential()\n",
    "\n",
    "    # Normalize input data\n",
    "    model2.add(tensorflow.keras.layers.BatchNormalization(input_shape=(11,)))\n",
    "\n",
    "    # Hidden layers\n",
    "    model2.add(Dense(512, activation='relu', kernel_initializer= 'he_normal'))\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(Dropout(0.2)) \n",
    "    model2.add(Dense(200, activation='relu', kernel_initializer= 'he_normal'))\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(Dropout(0.2)) \n",
    "    model2.add(Dense(100, activation='relu', kernel_initializer= 'he_normal'))\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(Dropout(0.2)) \n",
    "    # model2.add(Dense(50, activation= \"relu\", kernel_initializer= 'he_normal'))\n",
    "    # model2.add(BatchNormalization())\n",
    "    # model2.add(Dropout(0.2)) \n",
    "\n",
    "    # Output node\n",
    "    model2.add(Dense(9, activation='softmax')) #, kernel_initializer='glorot_uniform'))\n",
    "    \n",
    "    opt = Adam(lr=0.01)\n",
    "    \n",
    "    # Compile\n",
    "    model2.compile(loss= 'categorical_crossentropy' , optimizer=opt, metrics='accuracy')\n",
    "    result2 = model2.fit(X_train1, y_train1, batch_size=25, epochs=50, validation_split=0.2);\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "    score = model2.evaluate(X_train1, y_train1, verbose=0)\n",
    "    print(score)\n",
    "\n",
    "    step4_act1.insert(0,'Network Trained')\n",
    "    \n",
    "    cv2.delete(ylw)\n",
    "    grn = cv3.create_oval(10,10,25,25, fill='green')\n",
    "    \n",
    "#     score_t = model2.evaluate(X_test1, y_test1, verbose=0)\n",
    "#     print( score_t)\n",
    "\n",
    "# Saving Classifier model\n",
    "def save_c():\n",
    "    \n",
    "    global model2, red, ylw, grn\n",
    "    \n",
    "    cv3.delete(grn)\n",
    "    ylw = cv2.create_oval(10,10,25,25, fill='yellow')\n",
    "    \n",
    "    step4_act2.delete(0,'end')\n",
    "    model2.save('Classification.h5')\n",
    "    step4_act2.insert(0,'Model Saved')\n",
    "    \n",
    "    cv2.delete(ylw)\n",
    "    red = cv1.create_oval(10,10,25,25, fill='red')\n",
    "    ylw = cv2.create_oval(10,10,25,25, fill='yellow')\n",
    "    grn = cv3.create_oval(10,10,25,25, fill='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning variables and entry widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "file_var = tk.StringVar()\n",
    "file_act = tk.StringVar()\n",
    "trgt_var = tk.StringVar()\n",
    "trgt_act = tk.StringVar()\n",
    "trn_actr = tk.StringVar()\n",
    "pic_actr = tk.StringVar()\n",
    "trn_actc = tk.StringVar()\n",
    "pic_actc = tk.StringVar()\n",
    "\n",
    "# Labels and Entries\n",
    "step1_label = tk.Label(win, text = \"Step 1: File Name\", font=8)\n",
    "step1_ent = tk.Entry(win,textvariable = file_var, font=8)\n",
    "step1_act = tk.Entry(win,textvariable = file_act, font=8)\n",
    "\n",
    "step2_label =  tk.Label(win, text = \"Step 2: Target Column\", font=8)\n",
    "step2_ent = tk.Entry(win,textvariable = trgt_var, font=8)\n",
    "step2_act = tk.Entry(win,textvariable = trgt_act, font=8)\n",
    "\n",
    "step3_label = tk.Label(win, text = \"Step 3: Neural Network Regressor\", font=8)\n",
    "\n",
    "regres = tk.Label(win, text = \"Regression\", font=5)\n",
    "step3_act1 = tk.Entry(win,textvariable = trn_actr, font=8)\n",
    "\n",
    "pick_r = tk.Label(win, text = \"Pickle R-model\", font=5)\n",
    "step3_act2 = tk.Entry(win,textvariable = pic_actr, font=8)\n",
    "\n",
    "step4_label = tk.Label(win, text = \"Step 4: Neural Network Classifier\", font=8)\n",
    "\n",
    "clasfr = tk.Label(win, text = \"Classifier\", font=5)\n",
    "step4_act1 = tk.Entry(win,textvariable = trn_actc, font=8)\n",
    "\n",
    "pick_c = tk.Label(win, text = \"Pickle C-model\", font=5)\n",
    "step4_act2 = tk.Entry(win,textvariable = pic_actc, font=8)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning commands to buttons, organizing the layout and calling the main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rakesh Gowda S N\\anaconda3\\lib\\tkinter\\__init__.py\", line 1883, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-50-33a2b97826bd>\", line 42, in import_trgt\n",
      "    indata = df.drop([sel_col], axis=1)\n",
      "  File \"C:\\Users\\Rakesh Gowda S N\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 3990, in drop\n",
      "    return super().drop(\n",
      "  File \"C:\\Users\\Rakesh Gowda S N\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 3936, in drop\n",
      "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "  File \"C:\\Users\\Rakesh Gowda S N\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 3970, in _drop_axis\n",
      "    new_axis = axis.drop(labels, errors=errors)\n",
      "  File \"C:\\Users\\Rakesh Gowda S N\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 5018, in drop\n",
      "    raise KeyError(f\"{labels[mask]} not found in axis\")\n",
      "KeyError: \"['s'] not found in axis\"\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rakesh Gowda S N\\anaconda3\\lib\\tkinter\\__init__.py\", line 1883, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-50-33a2b97826bd>\", line 42, in import_trgt\n",
      "    indata = df.drop([sel_col], axis=1)\n",
      "  File \"C:\\Users\\Rakesh Gowda S N\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 3990, in drop\n",
      "    return super().drop(\n",
      "  File \"C:\\Users\\Rakesh Gowda S N\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 3936, in drop\n",
      "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "  File \"C:\\Users\\Rakesh Gowda S N\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 3970, in _drop_axis\n",
      "    new_axis = axis.drop(labels, errors=errors)\n",
      "  File \"C:\\Users\\Rakesh Gowda S N\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 5018, in drop\n",
      "    raise KeyError(f\"{labels[mask]} not found in axis\")\n",
      "KeyError: \"['Signal_Strength'] not found in axis\"\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rakesh Gowda S N\\anaconda3\\lib\\tkinter\\__init__.py\", line 1883, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-50-33a2b97826bd>\", line 42, in import_trgt\n",
      "    indata = df.drop([sel_col], axis=1)\n",
      "  File \"C:\\Users\\Rakesh Gowda S N\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 3990, in drop\n",
      "    return super().drop(\n",
      "  File \"C:\\Users\\Rakesh Gowda S N\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 3936, in drop\n",
      "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "  File \"C:\\Users\\Rakesh Gowda S N\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 3970, in _drop_axis\n",
      "    new_axis = axis.drop(labels, errors=errors)\n",
      "  File \"C:\\Users\\Rakesh Gowda S N\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 5018, in drop\n",
      "    raise KeyError(f\"{labels[mask]} not found in axis\")\n",
      "KeyError: \"['Signal_Strength'] not found in axis\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "90/90 [==============================] - 1s 3ms/step - loss: 31.9807 - mse: 31.9807 - val_loss: 15.1346 - val_mse: 15.1346\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 21.8845 - mse: 21.8845 - val_loss: 9.3851 - val_mse: 9.3851\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 12.1621 - mse: 12.1621 - val_loss: 5.9060 - val_mse: 5.9060\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 5.0803 - mse: 5.0803 - val_loss: 2.2269 - val_mse: 2.2269\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 2.9224 - mse: 2.9224 - val_loss: 1.0367 - val_mse: 1.0367\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 2.5086 - mse: 2.5086 - val_loss: 0.6957 - val_mse: 0.6957\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 2.0007 - mse: 2.0007 - val_loss: 0.7884 - val_mse: 0.7884\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 2.3101 - mse: 2.3101 - val_loss: 0.7898 - val_mse: 0.7898\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 1.9454 - mse: 1.9454 - val_loss: 0.6963 - val_mse: 0.6963\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 1.7621 - mse: 1.7621 - val_loss: 0.6083 - val_mse: 0.6083\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 1.7409 - mse: 1.7409 - val_loss: 0.7097 - val_mse: 0.7097\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 1.5301 - mse: 1.5301 - val_loss: 0.5668 - val_mse: 0.5668\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 1.4065 - mse: 1.4065 - val_loss: 0.5555 - val_mse: 0.5555\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 1.3652 - mse: 1.3652 - val_loss: 0.5201 - val_mse: 0.5201\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 1.3277 - mse: 1.3277 - val_loss: 0.5439 - val_mse: 0.5439\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 1.2212 - mse: 1.2212 - val_loss: 0.5449 - val_mse: 0.5449\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 1.2896 - mse: 1.2896 - val_loss: 0.5096 - val_mse: 0.5096\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 1.0691 - mse: 1.0691 - val_loss: 0.4728 - val_mse: 0.4728\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 1.1844 - mse: 1.1844 - val_loss: 0.4920 - val_mse: 0.4920\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 1.0326 - mse: 1.0326 - val_loss: 0.4710 - val_mse: 0.4710\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 1.0296 - mse: 1.0296 - val_loss: 0.4700 - val_mse: 0.4700\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 1.0298 - mse: 1.0298 - val_loss: 0.4634 - val_mse: 0.4634\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.9179 - mse: 0.9179 - val_loss: 0.4546 - val_mse: 0.4546\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.8984 - mse: 0.8984 - val_loss: 0.4802 - val_mse: 0.4802\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.9854 - mse: 0.9854 - val_loss: 0.4721 - val_mse: 0.4721\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.9322 - mse: 0.9322 - val_loss: 0.4673 - val_mse: 0.4673\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.8269 - mse: 0.8269 - val_loss: 0.4257 - val_mse: 0.4257\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.8690 - mse: 0.8690 - val_loss: 0.4621 - val_mse: 0.4621\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.9366 - mse: 0.9366 - val_loss: 0.4557 - val_mse: 0.4557\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.9111 - mse: 0.9111 - val_loss: 0.4749 - val_mse: 0.4749\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.8481 - mse: 0.8481 - val_loss: 0.4794 - val_mse: 0.4794\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.8478 - mse: 0.8478 - val_loss: 0.4479 - val_mse: 0.4479\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7673 - mse: 0.7673 - val_loss: 0.4650 - val_mse: 0.4650\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.7549 - mse: 0.7549 - val_loss: 0.4285 - val_mse: 0.4285\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.8759 - mse: 0.8759 - val_loss: 0.4189 - val_mse: 0.4189\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.8205 - mse: 0.8205 - val_loss: 0.4414 - val_mse: 0.4414\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.7421 - mse: 0.7421 - val_loss: 0.4465 - val_mse: 0.4465\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.7234 - mse: 0.7234 - val_loss: 0.4219 - val_mse: 0.4219\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.7556 - mse: 0.7556 - val_loss: 0.4528 - val_mse: 0.4528\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.7482 - mse: 0.7482 - val_loss: 0.4636 - val_mse: 0.4636\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.7803 - mse: 0.7803 - val_loss: 0.4548 - val_mse: 0.4548\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6678 - mse: 0.6678 - val_loss: 0.4469 - val_mse: 0.4469\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.7982 - mse: 0.7982 - val_loss: 0.4277 - val_mse: 0.4277\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.7034 - mse: 0.7034 - val_loss: 0.4395 - val_mse: 0.4395\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6783 - mse: 0.6783 - val_loss: 0.4290 - val_mse: 0.4290\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.7439 - mse: 0.7439 - val_loss: 0.4266 - val_mse: 0.4266\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6825 - mse: 0.6825 - val_loss: 0.4144 - val_mse: 0.4144\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6637 - mse: 0.6637 - val_loss: 0.4447 - val_mse: 0.4447\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6664 - mse: 0.6664 - val_loss: 0.4794 - val_mse: 0.4794\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6923 - mse: 0.6923 - val_loss: 0.4398 - val_mse: 0.4398\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5998 - mse: 0.5998 - val_loss: 0.4200 - val_mse: 0.4200\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6807 - mse: 0.6807 - val_loss: 0.4393 - val_mse: 0.4393\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5641 - mse: 0.5641 - val_loss: 0.4088 - val_mse: 0.4088\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6454 - mse: 0.6454 - val_loss: 0.4221 - val_mse: 0.4221\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6496 - mse: 0.6496 - val_loss: 0.4430 - val_mse: 0.4430\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5578 - mse: 0.5578 - val_loss: 0.4412 - val_mse: 0.4412\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5958 - mse: 0.5958 - val_loss: 0.4654 - val_mse: 0.4654\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5598 - mse: 0.5598 - val_loss: 0.4204 - val_mse: 0.4204\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5887 - mse: 0.5887 - val_loss: 0.4047 - val_mse: 0.4047\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5282 - mse: 0.5282 - val_loss: 0.4313 - val_mse: 0.4313\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.7111 - mse: 0.7111 - val_loss: 0.4667 - val_mse: 0.4667\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5323 - mse: 0.5323 - val_loss: 0.4156 - val_mse: 0.4156\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5867 - mse: 0.5867 - val_loss: 0.4130 - val_mse: 0.4130\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6464 - mse: 0.6464 - val_loss: 0.4062 - val_mse: 0.4062\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5598 - mse: 0.5598 - val_loss: 0.4393 - val_mse: 0.4393\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5990 - mse: 0.5990 - val_loss: 0.4197 - val_mse: 0.4197\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6002 - mse: 0.6002 - val_loss: 0.4304 - val_mse: 0.4304\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5523 - mse: 0.5523 - val_loss: 0.4262 - val_mse: 0.4262\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5820 - mse: 0.5820 - val_loss: 0.4073 - val_mse: 0.4073\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6330 - mse: 0.6330 - val_loss: 0.4135 - val_mse: 0.4135\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5782 - mse: 0.5782 - val_loss: 0.4162 - val_mse: 0.4162\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5721 - mse: 0.5721 - val_loss: 0.4472 - val_mse: 0.4472\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6097 - mse: 0.6097 - val_loss: 0.4059 - val_mse: 0.4059\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5683 - mse: 0.5683 - val_loss: 0.4371 - val_mse: 0.4371\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5096 - mse: 0.5096 - val_loss: 0.4252 - val_mse: 0.4252\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5405 - mse: 0.5405 - val_loss: 0.4155 - val_mse: 0.4155\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5553 - mse: 0.5553 - val_loss: 0.4210 - val_mse: 0.4210\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5461 - mse: 0.5461 - val_loss: 0.4258 - val_mse: 0.4258\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6208 - mse: 0.6208 - val_loss: 0.4132 - val_mse: 0.4132\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5886 - mse: 0.5886 - val_loss: 0.4230 - val_mse: 0.4230\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5669 - mse: 0.5669 - val_loss: 0.4132 - val_mse: 0.4132\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6115 - mse: 0.6115 - val_loss: 0.4189 - val_mse: 0.4189\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6352 - mse: 0.6352 - val_loss: 0.4187 - val_mse: 0.4187\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5396 - mse: 0.5396 - val_loss: 0.4171 - val_mse: 0.4171\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5605 - mse: 0.5605 - val_loss: 0.4189 - val_mse: 0.4189\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6133 - mse: 0.6133 - val_loss: 0.4080 - val_mse: 0.4080\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.4775 - mse: 0.4775 - val_loss: 0.4017 - val_mse: 0.4017\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5784 - mse: 0.5784 - val_loss: 0.4111 - val_mse: 0.4111\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6040 - mse: 0.6040 - val_loss: 0.4006 - val_mse: 0.4006\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5192 - mse: 0.5192 - val_loss: 0.4213 - val_mse: 0.4213\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5196 - mse: 0.5196 - val_loss: 0.4184 - val_mse: 0.4184\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5350 - mse: 0.5350 - val_loss: 0.4177 - val_mse: 0.4177\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5828 - mse: 0.5828 - val_loss: 0.4120 - val_mse: 0.4120\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5221 - mse: 0.5221 - val_loss: 0.4249 - val_mse: 0.4249\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5021 - mse: 0.5021 - val_loss: 0.4009 - val_mse: 0.4009\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5274 - mse: 0.5274 - val_loss: 0.3915 - val_mse: 0.3915\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5586 - mse: 0.5586 - val_loss: 0.4298 - val_mse: 0.4298\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.4903 - mse: 0.4903 - val_loss: 0.4046 - val_mse: 0.4046\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5273 - mse: 0.5273 - val_loss: 0.4010 - val_mse: 0.4010\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5889 - mse: 0.5889 - val_loss: 0.4065 - val_mse: 0.4065\n",
      "\n",
      "0.5781175435242756\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 1s 7ms/step - loss: 2.1184 - accuracy: 0.4237 - val_loss: 34.6036 - val_accuracy: 0.0223\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 1.0532 - accuracy: 0.5737 - val_loss: 13.9807 - val_accuracy: 0.0223\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 1.0046 - accuracy: 0.5553 - val_loss: 3.9674 - val_accuracy: 0.1562\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.9037 - accuracy: 0.6149 - val_loss: 2.4446 - val_accuracy: 0.2411\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.9273 - accuracy: 0.5823 - val_loss: 1.3395 - val_accuracy: 0.3884\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.9032 - accuracy: 0.5883 - val_loss: 1.1605 - val_accuracy: 0.4688\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.9407 - accuracy: 0.5934 - val_loss: 1.0615 - val_accuracy: 0.5134\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8955 - accuracy: 0.6013 - val_loss: 1.1756 - val_accuracy: 0.5134\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8774 - accuracy: 0.6220 - val_loss: 1.0134 - val_accuracy: 0.5580\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8730 - accuracy: 0.6272 - val_loss: 0.9537 - val_accuracy: 0.6071\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8729 - accuracy: 0.6210 - val_loss: 1.0150 - val_accuracy: 0.5714\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8195 - accuracy: 0.6649 - val_loss: 1.0162 - val_accuracy: 0.5670\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8301 - accuracy: 0.6401 - val_loss: 0.9704 - val_accuracy: 0.6161\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8396 - accuracy: 0.6102 - val_loss: 1.0225 - val_accuracy: 0.5446\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8071 - accuracy: 0.6561 - val_loss: 0.9555 - val_accuracy: 0.5848\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.8396 - accuracy: 0.6191 - val_loss: 1.0105 - val_accuracy: 0.6161\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8359 - accuracy: 0.6459 - val_loss: 1.0134 - val_accuracy: 0.5312\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7922 - accuracy: 0.6658 - val_loss: 1.0587 - val_accuracy: 0.5625\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7635 - accuracy: 0.6828 - val_loss: 0.9189 - val_accuracy: 0.6205\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8078 - accuracy: 0.6399 - val_loss: 1.1001 - val_accuracy: 0.5357\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8380 - accuracy: 0.6649 - val_loss: 0.9823 - val_accuracy: 0.6205\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.8357 - accuracy: 0.6351 - val_loss: 0.9881 - val_accuracy: 0.5804\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7125 - accuracy: 0.6854 - val_loss: 1.0206 - val_accuracy: 0.5848\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7648 - accuracy: 0.6756 - val_loss: 1.0956 - val_accuracy: 0.5625\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7498 - accuracy: 0.6851 - val_loss: 1.2033 - val_accuracy: 0.5134\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7479 - accuracy: 0.6823 - val_loss: 1.0916 - val_accuracy: 0.6071\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7188 - accuracy: 0.6800 - val_loss: 1.0477 - val_accuracy: 0.6161\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.6631 - val_loss: 1.0804 - val_accuracy: 0.5670\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7546 - accuracy: 0.6904 - val_loss: 1.1734 - val_accuracy: 0.5134\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7229 - accuracy: 0.6749 - val_loss: 1.1994 - val_accuracy: 0.4643\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7501 - accuracy: 0.6739 - val_loss: 1.0526 - val_accuracy: 0.6071\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7210 - accuracy: 0.6678 - val_loss: 1.0446 - val_accuracy: 0.6205\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.6958 - accuracy: 0.6968 - val_loss: 1.1913 - val_accuracy: 0.5134\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7804 - accuracy: 0.6528 - val_loss: 1.0751 - val_accuracy: 0.6027\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7297 - accuracy: 0.6780 - val_loss: 1.0678 - val_accuracy: 0.5848\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7085 - accuracy: 0.6770 - val_loss: 1.0296 - val_accuracy: 0.6161\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.6667 - accuracy: 0.7369 - val_loss: 1.1162 - val_accuracy: 0.5893\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7026 - accuracy: 0.7170 - val_loss: 1.1103 - val_accuracy: 0.5893\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7264 - accuracy: 0.7007 - val_loss: 1.1231 - val_accuracy: 0.6071\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7066 - accuracy: 0.6980 - val_loss: 1.1532 - val_accuracy: 0.5491\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7803 - accuracy: 0.6815 - val_loss: 1.1402 - val_accuracy: 0.5848\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.6729 - accuracy: 0.7221 - val_loss: 1.0596 - val_accuracy: 0.5848\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.7133 - val_loss: 1.0741 - val_accuracy: 0.5938\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.7340 - val_loss: 1.2188 - val_accuracy: 0.5268\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7640 - accuracy: 0.6959 - val_loss: 1.1960 - val_accuracy: 0.5223\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7317 - accuracy: 0.7037 - val_loss: 1.1206 - val_accuracy: 0.6027\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.7199 - accuracy: 0.6848 - val_loss: 1.2213 - val_accuracy: 0.5536\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7123 - accuracy: 0.7050 - val_loss: 1.0728 - val_accuracy: 0.5759\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.7349 - val_loss: 1.0264 - val_accuracy: 0.6295\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.6838 - accuracy: 0.6983 - val_loss: 1.0853 - val_accuracy: 0.5893\n",
      "\n",
      "[0.6360476016998291, 0.7640750408172607]\n"
     ]
    }
   ],
   "source": [
    "# Buttons\n",
    "myfont = font.Font(size=13)\n",
    "\n",
    "file_btn = tk.Button(text=\"Import Data\", command=import_data, bg='light blue')\n",
    "file_btn['font'] = myfont\n",
    "\n",
    "trgt_btn = tk.Button(text=\"Import Target\", command=import_trgt, bg='light blue')\n",
    "trgt_btn['font'] = myfont\n",
    "\n",
    "trn_btnr = tk.Button(text=\"Train Model\", command=train_r, bg='yellow')\n",
    "trn_btnr['font'] = myfont\n",
    "\n",
    "pic_btnr = tk.Button(text=\"Save Model\", command=save_r, bg='light green')\n",
    "pic_btnr['font'] = myfont\n",
    "\n",
    "trn_btnc = tk.Button(text=\"Train Model\", command=train_c, bg='yellow')\n",
    "trn_btnc['font'] = myfont\n",
    "\n",
    "pic_btnc = tk.Button(text=\"Save Model\", command=save_c, bg='light green')\n",
    "pic_btnc['font'] = myfont\n",
    "\n",
    "    \n",
    "# Organizing using place\n",
    "step1_label.place(x=10, y=50)\n",
    "step1_ent.place(x=350, y=50)\n",
    "file_btn.place(x=610, y=50)\n",
    "step1_act.place(x=750,y=50)\n",
    "\n",
    "step2_label.place(x=10, y=100)\n",
    "step2_ent.place(x=350, y=100)\n",
    "trgt_btn.place(x=610, y=100)\n",
    "step2_act.place(x=750,y=100)\n",
    "\n",
    "step3_label.place(x=10, y=150)\n",
    "\n",
    "regres.place(x=210,y=200)\n",
    "trn_btnr.place(x=400, y=200)\n",
    "step3_act1.place(x=600, y=200)\n",
    "\n",
    "pick_r.place(x=180,y=250)\n",
    "pic_btnr.place(x=400, y=250)\n",
    "step3_act2.place(x=600, y=250)\n",
    "\n",
    "\n",
    "step4_label.place(x=10, y=300)\n",
    "\n",
    "clasfr.place(x=210,y=350)\n",
    "trn_btnc.place(x=400, y=350)\n",
    "step4_act1.place(x=600, y=350)\n",
    "\n",
    "pick_c.place(x=180,y=400)\n",
    "pic_btnc.place(x=400, y=400)\n",
    "step4_act2.place(x=600, y=400)\n",
    "\n",
    "# Canvas\n",
    "cv1.place(x=10, y=10)\n",
    "cv2.place(x=50, y=10)\n",
    "cv3.place(x=90, y=10)\n",
    "\n",
    "win.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, with the help of tkinter we have created a GUI to import, train, fit and evaluate Regression and Classifier models for Neural Networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
